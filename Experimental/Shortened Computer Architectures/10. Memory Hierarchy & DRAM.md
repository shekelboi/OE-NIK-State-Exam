# Memory Hierarchy & DRAM

### Why Not Use One Big Fast Memory?

Because speed and cost scale differently:

* **Fast memory (like SRAM)** is expensive and small.
* **Large memory (like DRAM)** is slower but cheaper.

So CPUs use a **hierarchy** of memories to balance speed and capacity.

---

### Principle of Locality

Programs tend to access:

* **Temporal locality**: the same data repeatedly in a short time.
* **Spatial locality**: data close to recently used data.

This behavior allows **caches** to be effective.

---

### Memory Hierarchy (Top â†’ Bottom)

| Level       | Speed     | Size   | Cost      |
|-------------|-----------|--------|-----------|
| Registers   | Very fast | Tiny   | Very high |
| L1 Cache    | Fast      | Small  | High      |
| L2/L3 Cache | Moderate  | Larger | Medium    |
| DRAM (Main) | Slower    | GBs    | Lower     |
| Disk/SSD    | Slowest   | TBs    | Cheapest  |

Each level **acts as a cache** for the level below it.

---

### DRAM Basics

* **DRAM** (Dynamic RAM) stores data as **charges in capacitors**.
* Needs **constant refreshing** (reads and rewrites contents every few ms).
* Slower than SRAM (used in caches) but **denser and cheaper**.

---

### Memory Width Effects

* **Wider memory buses** (e.g. 64-bit vs 128-bit) can transfer more data per cycle.
* Affects how quickly large blocks of data can be read/written.

---

### Interleaving

* Technique to improve throughput by **splitting memory into banks**.
* Allows **parallel access** to different banks, reducing wait time.
